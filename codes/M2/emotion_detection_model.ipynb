{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_detection_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "c20fc95db3b40254a0f279ab91850c932b876113fc826ccf7319e2b425683a1a"
      }
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "21sNgF4Ydag2"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PaavbLUd-NF"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "api_token = {\"username\":\"yishengliu\",\"key\":\"600d4a6327f17945c27ff54c8bae7bad\"}\n",
        "import json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip /content/challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "!rm -rf /content/train.csv /content/test.csv /content/icml_face_data.csv /content/example_submission.csv /content/challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "!tar -xzf /content/fer2013.tar.gz\n",
        "!mkdir dataset\n",
        "!mkdir dataset/fer2013\n",
        "!mv /content/fer2013/fer2013.csv /content/dataset/fer2013\n",
        "!rm -rf /content/fer2013 /content/fer2013.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPz4CIqh6cT"
      },
      "source": [
        "class dataset_provider(object):\n",
        "    def __init__(self, img_size):\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def dataset_initializer(self):\n",
        "        pixels_from_csv = pd.read_csv('/content/dataset/fer2013/fer2013.csv')\n",
        "        pixels_list = pixels_from_csv['pixels'].tolist()\n",
        "        ds_emotions = pd.get_dummies(pixels_from_csv['emotion']).values\n",
        "        ds_faces = []\n",
        "        for pixel_in_sequence in pixels_list:\n",
        "            face = [int(pixel) for pixel in pixel_in_sequence.split(' ')]\n",
        "            face = np.asarray(face).reshape(48, 48)\n",
        "            face = cv2.resize(face.astype('uint8'), self.img_size)\n",
        "            ds_faces.append(face.astype('float32'))\n",
        "        ds_faces = np.expand_dims(np.asarray(ds_faces), -1)\n",
        "        return ds_faces, ds_emotions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mnouTyYh_cw"
      },
      "source": [
        "dataset = dataset_provider((64,64))\n",
        "faces, emotions = dataset.dataset_initializer()\n",
        "faces = faces.astype('float32')\n",
        "faces = ((faces / 255.0) - 0.5) * 2.0\n",
        "n_train = int(0.8 * len(faces))\n",
        "n_test = len(faces) - n_train\n",
        "ds_train_faces = faces[:n_train]\n",
        "ds_train_emotions = emotions[:n_train]\n",
        "ds_test_faces = faces[n_train:]\n",
        "ds_test_emotions = emotions[n_train:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkyHbjYKyK03"
      },
      "source": [
        "def base_model(input_shape, classes_no):\n",
        "  input_data = keras.layers.Input(input_shape)\n",
        "  model = keras.layers.Convolution2D(8,(3,3))(input_data)\n",
        "  model = keras.layers.BatchNormalization()(model)\n",
        "  model = keras.layers.Activation('relu')(model)\n",
        "  my_filters = [16,64,256,512]\n",
        "  for filter in my_filters:\n",
        "    model = keras.layers.Convolution2D(filter,(3,3),padding='same')(model)\n",
        "    model = keras.layers.BatchNormalization()(model)\n",
        "    model = keras.layers.Activation('relu')(model)\n",
        "    model = keras.layers.Convolution2D(filter,(3,3),padding='same')(model)\n",
        "    model = keras.layers.BatchNormalization()(model)\n",
        "    model = keras.layers.MaxPooling2D(pool_size=(2,2), padding='same')(model)\n",
        "    model = keras.layers.Activation('relu')(model)\n",
        "  model = keras.layers.Convolution2D(classes_no,(3,3),padding='same')(model)\n",
        "  model = keras.layers.GlobalMaxPooling2D()(model)\n",
        "  ret_model = keras.models.Model(input_data, keras.layers.Activation('softmax',name='predictions')(model))\n",
        "  return ret_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLSGhWQcm8Ok"
      },
      "source": [
        "input_shape = (64,64,1)\n",
        "classes_no = 7\n",
        "batch = 4\n",
        "model = base_model(input_shape, classes_no)\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(epochs=100,\n",
        "     x=keras.preprocessing.image.ImageDataGenerator(\n",
        "     horizontal_flip=True,\n",
        "     rotation_range=15,\n",
        "     width_shift_range=0.1,\n",
        "     height_shift_range=0.1,\n",
        "     zoom_range=0.1\n",
        "     ).flow(ds_train_faces,ds_train_emotions,batch),\n",
        "     validation_data=(ds_test_faces,ds_test_emotions),\n",
        "     steps_per_epoch=len(ds_train_faces)/batch)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
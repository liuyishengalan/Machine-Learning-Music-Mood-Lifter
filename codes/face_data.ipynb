{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone1-face-training-part.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9WlhAx3HI44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20440deb-c4d2-4982-fab6-337ae03cb142"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"yishengliu\",\"key\":\"600d4a6327f17945c27ff54c8bae7bad\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 24.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 22.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=0ab5bfc8e57e932a98806c998ed2fc7bb5f652f52aa6aad4694f49f128f9a051\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQEAMtq3HSmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdab05df-a820-41c4-ce56-ecc6923c4b35"
      },
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 98% 280M/285M [00:03<00:00, 134MB/s]\n",
            "100% 285M/285M [00:03<00:00, 74.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euDWuosVMWmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc0914d-e3bd-492d-8974-fc4b2d5f6c52"
      },
      "source": [
        "!unzip /content/challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "!rm -rf /content/train.csv /content/test.csv /content/icml_face_data.csv /content/example_submission.csv /content/challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "!tar -xzf /content/fer2013.tar.gz\n",
        "!mkdir dataset\n",
        "!mkdir dataset/fer2013\n",
        "!mv /content/fer2013/fer2013.csv /content/dataset/fer2013\n",
        "!rm -rf /content/fer2013 /content/fer2013.tar.gz\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqj6akQ-AsGE"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaVScFqAbZwk"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bkVW4NBOwOb"
      },
      "source": [
        "class dataset_provider(object):\n",
        "    def __init__(self, dataset_name, image_size):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.image_size = image_size\n",
        "        self.dataset_path = '/content/dataset/fer2013/fer2013.csv'\n",
        "\n",
        "    def dataset_initializer(self):\n",
        "        data = pd.read_csv(self.dataset_path)\n",
        "        pixels = data['pixels'].tolist()\n",
        "        width = 48\n",
        "        height = 48\n",
        "        faces = []\n",
        "        for pixel_sequence in pixels:\n",
        "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "            face = np.asarray(face).reshape(width, height)\n",
        "            face = cv2.resize(face.astype('uint8'), self.image_size)\n",
        "            faces.append(face.astype('float32'))\n",
        "        faces = np.asarray(faces)\n",
        "        faces = np.expand_dims(faces, -1)\n",
        "        emotions = pd.get_dummies(data['emotion']).values\n",
        "        return faces, emotions\n",
        "\n",
        "def get_labels(dataset_name):\n",
        "    if dataset_name == 'fer2013':\n",
        "        return {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'sad', 5: 'surprise', 6: 'neutral'}\n",
        "    else:\n",
        "        raise Exception('Invalid args: Wrong dataset name.')\n",
        "\n",
        "\n",
        "def get_class_to_arg(dataset_name):\n",
        "    if dataset_name == 'fer2013':\n",
        "        return {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'sad': 4, 'surprise': 5, 'neutral': 6}\n",
        "    else:\n",
        "        raise Exception('Invalid args: Wrong dataset name.')\n",
        "\n",
        "\n",
        "def pre_process(x, _is=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if _is:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVRUV_wNTW-d"
      },
      "source": [
        "input_shape = (64, 64, 1)\n",
        "dataset = dataset_provider('fer2013', image_size=input_shape[:2])\n",
        "faces, emotions = dataset.dataset_initializer()\n",
        "faces = pre_process(faces)\n",
        "n_train = int(0.8 * len(faces))\n",
        "n_test = len(faces) - n_train\n",
        "rng = torch.Generator().manual_seed(291)\n",
        "ds_train_faces, ds_test_faces = torch.utils.data.random_split(faces, [n_train, n_test], rng)\n",
        "ds_train_emotions, ds_test_emotions = torch.utils.data.random_split(emotions, [n_train, n_test], rng)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}